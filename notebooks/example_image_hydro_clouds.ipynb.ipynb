{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa79828b",
   "metadata": {},
   "source": [
    "# Picture Perfect Fluids\n",
    "\n",
    "In this notebook we will take an image and turn it into a hydrodynamical simulation. To do this we first need to ingest an image, then convert each pixel into a particle distribution with positions, masses, densities, velocities and internal energies. Finally we will write this out to a SWIFT snapshot file.\n",
    "\n",
    "Please do upload your own images to try this out with and post results to the workshop Slack channel. To upload your own images, I recommend using `rsync` to transfer them from your local machine to Cosma, e.g. \n",
    "\n",
    "```bash\n",
    "rsync -avz -P /path/to/local/image.png <user>@login8.cosma.dur.ac.uk:/path/to/remote/directory/\n",
    "```\n",
    "\n",
    "Note that the image should be a PNG or JPG file, and ideally be square. The simulaiton itself will be square so non-square images will be distorted.\n",
    "\n",
    "You can find various example notebooks with modified images in this same directory called `example_image_hydro_XXX.ipynb`. These examples show different ways you can modify the particle properties to get different effects.\n",
    "\n",
    "This whole notebook was adapted from a workshop run by [Josh Borrow at SWIFTCon in 2023](https://github.com/JBorrow/image_to_particles).\n",
    "\n",
    "## Setting everything up\n",
    "\n",
    "In the cell below we import the necessary libraries and set up some useful constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f119e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import unyt\n",
    "import PIL\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from swiftsimio import load\n",
    "from swiftsimio import Writer\n",
    "from swiftsimio.visualisation import project_gas\n",
    "\n",
    "\n",
    "# Path to the image \n",
    "filepath = Path(\"images/squ_kh_clouds.png\")\n",
    "\n",
    "# Define the IC filename \n",
    "ic_filename = filepath.stem + \"_ic.hdf5\"\n",
    "\n",
    "print(\"Image filepath:\", filepath)\n",
    "print(\"IC filename:\", ic_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998184a5",
   "metadata": {},
   "source": [
    "Next we will open the image and resize it, to limit the cost of the simulation since we only have limited resources shared between us. We want to aim for between 128 and 256 pixels on a side. While you could do more you may struggle to get the allocation to run it, so keep this in mind!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dde307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the downsampling factor\n",
    "downsample = 4\n",
    "\n",
    "# Open the image\n",
    "image = PIL.Image.open(filepath)\n",
    "\n",
    "# Get the original size\n",
    "orig_size = image.size\n",
    "print(\"Original image size:\", orig_size)\n",
    "\n",
    "# Downsample the image \n",
    "IMAGE_SIZE = (orig_size[0] // downsample, orig_size[1] // downsample)\n",
    "print(\"Downsampled image size:\", IMAGE_SIZE)\n",
    "\n",
    "# Resize the image\n",
    "resized = image.resize((IMAGE_SIZE[0], IMAGE_SIZE[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cf5a94",
   "metadata": {},
   "source": [
    "For simplicities sake we will derive particles from a greyscale version of the image. As you've seen, it's possible to do colour images but this requires a slightly different approach which I leave to you as an extension challenge. \n",
    "\n",
    "In the cell below, we convert to greyscale and posterize the image to reduce the number of colours to 256. This helps later when we make particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d20941",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale = PIL.ImageOps.grayscale(resized)\n",
    "posterized = PIL.ImageOps.posterize(grayscale, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e87e9b8",
   "metadata": {},
   "source": [
    "Lets now plot the image just to check it looks OK. If not, by all means go back and adjust the setup or change the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7770e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(posterized)\n",
    "plt.title(\"Posterized image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955ff94b",
   "metadata": {},
   "source": [
    "## Pixels to Particles \n",
    "\n",
    "Now we need to derive particles from each pixels. We do this by simply sampling each pixel based on the \"density\" (i.e. brightness) of the pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d9e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def particles_from_image(posterized, levels=10):\n",
    "    \"\"\"\n",
    "    Convert a posterized grayscale image into particle coordinates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    posterized : array-like (H, W)\n",
    "        Image values in [0, 255].\n",
    "    levels : int\n",
    "        Number of density levels to use.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xs, ys, dens : np.ndarray\n",
    "        Particle coordinates (x, y) and density level per particle.\n",
    "    \"\"\"\n",
    "    # Get the width and height of the image \n",
    "    H, W = posterized.size \n",
    "\n",
    "    densities = (np.array(posterized).T // levels) + 1\n",
    "    print(densities.shape)\n",
    "    xs = []\n",
    "    ys = []\n",
    "    dens = []\n",
    "    for x in np.arange(IMAGE_SIZE[0]):\n",
    "        for y in np.arange(IMAGE_SIZE[1]):\n",
    "            density = densities[x, y]\n",
    "\n",
    "            these_xs, these_ys = np.meshgrid(\n",
    "                *[(np.arange(density) + 0.5) / float(density)] * 2\n",
    "            )\n",
    "\n",
    "            xs.extend(list((these_xs + float(x)).flat))\n",
    "            ys.extend(list((these_ys + float(y)).flat))\n",
    "            dens.extend([density] * these_xs.size)\n",
    "\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    dens = np.array(dens)\n",
    "    \n",
    "    #Scale\n",
    "    xs= xs / W\n",
    "    ys= ys / H\n",
    "\n",
    "    return xs, ys, dens\n",
    "\n",
    "# Convert the image to particles \n",
    "xs, ys, dens = particles_from_image(posterized, levels=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588440b7",
   "metadata": {},
   "source": [
    "Lets check everything looks OK by plotting the particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947405ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.hist2d(xs, -ys, norm=LogNorm(), bins=IMAGE_SIZE)\n",
    "plt.colorbar(h[3], label=\"Number of particles per pixel\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Particle distribution\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6e3d68",
   "metadata": {},
   "source": [
    "Now we have the particles, we just need to create a SWIFT ICs file. To do this we can make use of the [`swiftsimio`](https://swiftsimio.readthedocs.io/en/latest/) library, which has a convenient function to write out a snapshot file.\n",
    "\n",
    "To do this we will define a lot of the particle properties to be constant, but you can of course modify this to get different effects. For example, you could make the internal energy depend on the pixel brightness, add some random velocity dispersion to the particles, or localise a spike in internal energy to seed an explosion. \n",
    "\n",
    "You can see examples of this in the other example notebooks in this directory. However, it is very easy to create a pathological situation which could break or require adjustments to parameters. If you do run into issues, just let us know and we can help. (But dumping 10**100 cm / s^2 of energy into a particle is probably not a good idea!)\n",
    "\n",
    "Finally we write out the snapshot file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ed9e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the unit boxsize\n",
    "boxsize = (1.0 * unyt.cm, 1.0 * unyt.cm)\n",
    "print(\"Boxsize:\", boxsize, \"Npart:\", len(xs))\n",
    "\n",
    "# Create the IC writer\n",
    "x = Writer(\"cgs\", boxsize, dimension=2)\n",
    "\n",
    "# Particle count\n",
    "n_p = len(xs)\n",
    "\n",
    "# Make some velocities (here just a shear flow based on density)\n",
    "vels = np.zeros((xs.size, 3))\n",
    "okinds = dens / dens.max() > 0.5\n",
    "vels[okinds, 0] = 0.5\n",
    "vels[~okinds, 0] = -0.05\n",
    "\n",
    "# Attach the coordinates and velocities\n",
    "x.gas.coordinates = np.array([xs, ys, np.zeros_like(xs)]).T * unyt.cm\n",
    "x.gas.velocities = vels * (unyt.cm / unyt.s)\n",
    "\n",
    "# Constant mass for each particle\n",
    "mass = np.ones(n_p, dtype=float)\n",
    "x.gas.masses = mass * unyt.g\n",
    "\n",
    "# Constant small internal energy for each particle\n",
    "x.gas.internal_energy = np.ones(n_p, dtype=float) * 1e-3 * (unyt.cm / unyt.s) ** 2\n",
    "\n",
    "# Calculate the smoothing lengths \n",
    "x.gas.generate_smoothing_lengths(boxsize=boxsize, dimension=2)\n",
    "\n",
    "# Write out the ICs \n",
    "x.write(ic_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4d4216",
   "metadata": {},
   "source": [
    "If you want to explore what is in the IC file I recommend exploring it on the command line with [`h5forest`](https://github.com/WillJRoper/h5forest). This can be installed with `pip isntall h5forest` and then you can run `h5forest <filename>` to explore the contents of the file. \n",
    "\n",
    "(This definitely isn't shameless self-promotion for a package I wrote to explore HDF5 files...)\n",
    "\n",
    "## Defining the parameter file\n",
    "\n",
    "We're nearly there now, just need a parameter file which can be created easily using the function below. This should be fine as is, but you may want to adjust the `time_end` argument depending on how long a video you when you are finished. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2c5338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_swift_parameter_file(ic_filename, snap_name='kelvin_helmholtz', visc_alpha=0.8, time_end=1.0):\n",
    "    \"\"\"\n",
    "    Create a SWIFT parameter file for the Kelvin-Helmholtz simulation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs('../params', exist_ok=True)\n",
    "    param_file = f'../params/{snap_name}.yml'\n",
    "\n",
    "    # Ensure snapshots directory exists\n",
    "    os.makedirs(f'snapshots/{snap_name}', exist_ok=True)\n",
    "\n",
    "    param_content = f\"\"\"\n",
    "# Define the system of units to use internally. \n",
    "InternalUnitSystem:\n",
    "  UnitMass_in_cgs:     1   # g \n",
    "  UnitLength_in_cgs:   1   # cm\n",
    "  UnitVelocity_in_cgs: 1   # cm/s  \n",
    "  UnitCurrent_in_cgs:  1   # amperes\n",
    "  UnitTemp_in_cgs:     1   # kelvin\n",
    "\n",
    "# Parameters governing the time integration\n",
    "TimeIntegration:\n",
    "  time_begin: 0.0    # The starting time of the simulation (in internal units).\n",
    "  time_end:   {time_end}   # The end time of the simulation (in internal units).\n",
    "  dt_min:     1e-6  # The minimal time-step size of the simulation (in internal units).\n",
    "  dt_max:     1e-2  # The maximal time-step size of the simulation (in internal units).\n",
    "\n",
    "\n",
    "# Parameters governing the snapshots\n",
    "Snapshots:\n",
    "  basename:            snapshots/{snap_name}/{snap_name}  # Common part of the name of output files\n",
    "  time_first:          0.               # Time of the first output (in internal units)\n",
    "  delta_time:          0.01      # Time difference between consecutive outputs (in internal units)\n",
    "  compression:         1              # GZIP compression level (0-9)\n",
    "\n",
    "# Parameters governing the conserved quantities statistics\n",
    "Statistics:\n",
    "  delta_time:          0.01    # Time between statistics output\n",
    "\n",
    "Scheduler:\n",
    "  max_top_level_cells: 8\n",
    "\n",
    "# Parameters for the hydrodynamics scheme\n",
    "SPH:\n",
    "  resolution_eta:        1.2348   # Target smoothing length in units of the mean inter-particle separation\n",
    "  CFL_condition:         0.1      # Courant-Friedrichs-Levy condition for time integration\n",
    "  viscosity_alpha:       {visc_alpha}     # (Optional) Override for the initial value of the artificial viscosity. In schemes that have a fixed AV, this remains as alpha throughout the run.\n",
    "\n",
    "\n",
    "# Parameters related to the initial conditions\n",
    "InitialConditions:\n",
    "  file_name:  {ic_filename}    # The file to read\n",
    "  periodic:   1                       # Periodic boundary conditions\n",
    "\"\"\"\n",
    "    \n",
    "    with open(param_file, 'w') as f:\n",
    "        f.write(param_content)\n",
    "    \n",
    "    print(f\"Created parameter file: {param_file}\")\n",
    "    return param_file\n",
    "\n",
    "# Create parameter file\n",
    "param_file = create_swift_parameter_file(ic_filename, snap_name=filepath.stem, time_end=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22006c90",
   "metadata": {},
   "source": [
    "## Configuring and compiling SWIFT \n",
    "\n",
    "To run the simulation we need to configure and compile SWIFT to run a 2D hydrodynamics simulation. This is done in the cell below (but assumes you have run the setup script that defines the relevant environment variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ../swiftsim\n",
    "./configure \\\n",
    "  --with-hydro=sphenix \\\n",
    "  --with-hydro-dimension=2 \\\n",
    "  --enable-ipo \\\n",
    "  --with-kernel=wendland-C2 \\\n",
    "  --disable-mpi\n",
    "make -j\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0c09b6",
   "metadata": {},
   "source": [
    "## Running SWIFT \n",
    "\n",
    "Now we are ready to run SWIFT. This can be done by running a SLURM submission script which we generate below. This is so we can run with a suitable amount of resource without overloading the shared system. You may sit in the queue for a short while but the simulations should run quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a18424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_slurm_script(param_file, job_name='swift-img', time_limit='00:10:00', nthreads=8):\n",
    "    \"\"\"\n",
    "    Generate a SLURM submission script to run SWIFT with the given parameter file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs('slurm_scripts', exist_ok=True)\n",
    "    script_file = f'slurm_scripts/submit_{job_name}.sh'\n",
    "    \n",
    "    script_content = f\"\"\"#!/bin/bash -l\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH -J {job_name}\n",
    "#SBATCH --output=log_%j.txt\n",
    "#SBATCH -p dine2\n",
    "#SBATCH -A do020\n",
    "#SBATCH --cpus-per-task={nthreads}\n",
    "#SBATCH --time={time_limit}\n",
    "\n",
    "module purge\n",
    "module load intel_comp/2024.2.0 compiler-rt tbb compiler mpi ucx/1.17.0 parallel_hdf5/1.14.4 fftw/3.3.10 parmetis/4.0.3-64bit gsl/2.8\n",
    "\n",
    "../swiftsim/swift --hydro --threads=$SLURM_CPUS_PER_TASK {param_file}\n",
    "\n",
    "echo \"Job done, info follows...\"\n",
    "sacct -j $SLURM_JOBID --format=JobID,JobName,Partition,AveRSS,MaxRSS,AveVMSize,MaxVMSize,Elapsed,ExitCode\n",
    "exit\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    with open(script_file, 'w') as f:\n",
    "        f.write(script_content)\n",
    "\n",
    "    print(f\"SLURM submission script generated: {script_file}\")\n",
    "\n",
    "generate_slurm_script(param_file, job_name=filepath.stem, time_limit='00:10:00', nthreads=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8209bb",
   "metadata": {},
   "source": [
    "Now we just submit the job to the queue and wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd000e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "sbatch submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab248eef",
   "metadata": {},
   "source": [
    "If you want to check on the run you can use the `squeue --m` command to see the status of your jobs. Don't move on to the next cell before your job has finished!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a093bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "squeue --m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779de6cc",
   "metadata": {},
   "source": [
    "## Visualising the results \n",
    "\n",
    "In the cell below we make a video using `swiftsimio` to load the snapshots and `matplotlib` to make a video. You can adjust the `interval` argument to change the speed of the video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d20689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "\n",
    "def load_and_extract(filename):\n",
    "    \"\"\"\n",
    "    Load the data and extract relevant info.\n",
    "    \"\"\"\n",
    "\n",
    "    return load(filename)\n",
    "\n",
    "\n",
    "def make_plot(filename, array, nx, ny, dx, dy):\n",
    "    \"\"\"\n",
    "    Plot this frame. \n",
    "\n",
    "    Load the data and plop it on the grid using nearest\n",
    "    neighbour searching for finding the 'correct' value of\n",
    "    the density.\n",
    "    \"\"\"\n",
    "\n",
    "    data = load_and_extract(filename)\n",
    "\n",
    "    mesh = project_gas(data, nx).T.value\n",
    "\n",
    "    array.set_array(mesh)\n",
    "\n",
    "    return (array,)\n",
    "\n",
    "\n",
    "def frame(n, *args):\n",
    "    \"\"\"\n",
    "    Make a single frame. Requires the global variables plot and dpi.\n",
    "    \"\"\"\n",
    "\n",
    "    global plot, dpi\n",
    "\n",
    "    return make_plot(snapshot_files[n], plot, dpi, dpi, (0, 1), (0, 1))\n",
    "\n",
    "\n",
    "# Look for snapshot files matching the current run\n",
    "snapshot_files = sorted(glob.glob(f'snapshots/{filepath.stem}/{filepath.stem}_*.hdf5'))\n",
    "print(f\"Found {len(snapshot_files)} snapshot files.\")\n",
    "\n",
    "# Define the resolution of the output movie\n",
    "dpi = 512\n",
    "\n",
    "# Create a progress bar for feedback\n",
    "frames = tqdm(np.arange(0, len(snapshot_files)), desc=\"Making frames\")\n",
    "\n",
    "# Set up the plot itself\n",
    "fig, ax = plt.subplots(1, 1, figsize=(1, 1), frameon=False)\n",
    "ax.axis(\"off\")  # Remove annoying black frame.\n",
    "\n",
    "# Load the first frame to get the normalisation\n",
    "data = load_and_extract(snapshot_files[0])\n",
    "\n",
    "# Create the first frame\n",
    "mesh = project_gas(data, dpi).T.value\n",
    "\n",
    "# Get the normalising percentiles from the first frame \n",
    "vmin = np.percentile(mesh, 5)\n",
    "vmax = np.percentile(mesh, 99)\n",
    "\n",
    "# Make the plot with the first frame so we can update it during the animation\n",
    "plot = ax.imshow(\n",
    "    mesh,\n",
    "    extent=[0, 1, 0, 1],\n",
    "    animated=True,\n",
    "    interpolation=\"none\",\n",
    "    cmap=\"plasma\",\n",
    "    norm=LogNorm(vmin=vmin, vmax=vmax, clip=True)\n",
    ")\n",
    "\n",
    "# Setup the  animation\n",
    "anim = FuncAnimation(fig, frame, frames, interval=40, blit=False)\n",
    "\n",
    "# Remove all whitespace\n",
    "fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n",
    "\n",
    "# Actually make the movie\n",
    "anim.save(\"videos/\" + filepath.stem + \".mp4\", dpi=dpi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d357ef1",
   "metadata": {},
   "source": [
    "Once the video has been made, you can download it to your local machine using `rsync` in reverse to how you uploaded the image, e.g.\n",
    "\n",
    "```bash\n",
    "rsync -avz -P <user>@login8.cosma.dur.ac.uk:/path/to/movie.mp4 /path/to/local/directory/\n",
    "``` \n",
    "\n",
    "Please share the videos you've made on the workshop Slack channel!\n",
    "\n",
    "If you want to play with more \"real world\" examples, SWIFT comes with a large suite of examples in the `examples/` directory of the SWIFT repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5462a99a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthesizer-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
